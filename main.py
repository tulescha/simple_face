import cv2
import torch
import numpy as np
import pickle
import os
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
import warnings

warnings.filterwarnings('ignore')


class WorkingFaceRecognition:
    def __init__(self, threshold=0.7):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

        # –ü—Ä–æ—Å—Ç–æ–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ü –Ω–∞ –æ—Å–Ω–æ–≤–µ OpenCV
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        self.threshold = threshold
        self.embeddings_db = {}
        self.load_database()

    def load_database(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        if os.path.exists('face_embeddings.pkl'):
            with open('face_embeddings.pkl', 'rb') as f:
                self.embeddings_db = pickle.load(f)
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.embeddings_db)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        else:
            print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ —Å–≤–æ–µ –ª–∏—Ü–æ.")

    def save_database(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        with open('face_embeddings.pkl', 'wb') as f:
            pickle.dump(self.embeddings_db, f)
        print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

    def setup_camera(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –∫–∞–º–µ—Ä
        for camera_index in [0, 1]:
            cap = cv2.VideoCapture(camera_index)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f"‚úÖ –ö–∞–º–µ—Ä–∞ {camera_index} —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
                    return cap
            cap.release()

        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—Ç–∞—é—â—É—é –∫–∞–º–µ—Ä—É!")
        return None

    def extract_face_features(self, face_image):
        """
        –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –ª–∏—Ü–∞
        –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å
        """
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ grayscale –∏ –∏–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
            resized_face = cv2.resize(gray_face, (64, 64))

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            normalized_face = resized_face / 255.0

            # –í—ã—á–∏—Å–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (HOG) –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–∑–Ω–∞–∫
            hog_features = self.calculate_hog_features(normalized_face)

            # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–∏–µ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            hist_features = cv2.calcHist([gray_face], [0], None, [16], [0, 256]).flatten()
            hist_features = hist_features / np.sum(hist_features)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            combined_features = np.concatenate([hog_features, hist_features])

            # –î–æ–±–∏–≤–∞–µ–º –¥–æ 512 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (–∫–∞–∫ –≤ FaceNet)
            if len(combined_features) < 512:
                padding = np.zeros(512 - len(combined_features))
                combined_features = np.concatenate([combined_features, padding])
            else:
                combined_features = combined_features[:512]

            return combined_features.astype(np.float32)

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return np.random.randn(512).astype(np.float32)

    def calculate_hog_features(self, image):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ HOG –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è HOG
            gx = cv2.Sobel(image, cv2.CV_32F, 1, 0)
            gy = cv2.Sobel(image, cv2.CV_32F, 0, 1)

            mag, ang = cv2.cartToPolar(gx, gy)

            # –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
            bins = np.int32(8 * ang / (2 * np.pi))

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —è—á–µ–π–∫–∏ 8x8
            cell_size = 8
            h, w = image.shape
            hog_features = []

            for i in range(0, h - cell_size, cell_size):
                for j in range(0, w - cell_size, cell_size):
                    cell_mag = mag[i:i + cell_size, j:j + cell_size]
                    cell_bins = bins[i:i + cell_size, j:j + cell_size]

                    hist = np.zeros(8)
                    for bin_val in range(8):
                        hist[bin_val] = np.sum(cell_mag[cell_bins == bin_val])

                    # L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                    hist = hist / (np.linalg.norm(hist) + 1e-6)
                    hog_features.extend(hist)

            return np.array(hog_features).astype(np.float32)

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ HOG: {e}")
            return np.zeros(128).astype(np.float32)

    def detect_face(self, frame):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞ —Å –ø–æ–º–æ—â—å—é OpenCV"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(100, 100),  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            if len(faces) > 0:
                x, y, w, h = faces[0]
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–µ –ª–∏—Ü–æ
                face_img = frame[y:y + h, x:x + w]
                return face_img, [x, y, x + w, y + h]

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞: {e}")

        return None, None

    def register_face(self, name, num_samples=5):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ª–∏—Ü–∞"""
        print(f"–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {name}")

        cap = self.setup_camera()
        if cap is None:
            return False

        print("‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞! –°–º–æ—Ç—Ä–∏—Ç–µ –≤ –∫–∞–º–µ—Ä—É...")

        embeddings = []
        sample_count = 0

        while sample_count < num_samples:
            ret, frame = cap.read()
            if not ret:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä")
                continue

            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞
            face_img, box = self.detect_face(frame)

            display_frame = frame.copy()

            if face_img is not None and box is not None:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                embedding = self.extract_face_features(face_img)
                embeddings.append(embedding)
                sample_count += 1

                print(f"‚úÖ –û–±—Ä–∞–∑–µ—Ü {sample_count}/{num_samples} –ø–æ–ª—É—á–µ–Ω")

                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                x1, y1, x2, y2 = box
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(display_frame, f"Sample: {sample_count}", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –ª–∏—Ü–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                if sample_count == 1:
                    cv2.imwrite(f"face_sample_{name}.jpg", face_img)
            else:
                cv2.putText(display_frame, "No face detected", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            cv2.imshow('Face Registration', display_frame)

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –æ–±—Ä–∞–∑—Ü–∞–º–∏
            key = cv2.waitKey(1000) & 0xFF
            if key == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

        if embeddings:
            # –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            avg_embedding = np.mean(embeddings, axis=0)
            self.embeddings_db[name] = avg_embedding
            self.save_database()
            print(f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {name} —É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω!")
            return True
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            return False

    def recognize_face(self, embedding):
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥—É"""
        if not self.embeddings_db:
            return "No database", 0.0

        best_similarity = 0.0
        best_name = "Unknown"

        for name, db_embedding in self.embeddings_db.items():
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarity = cosine_similarity([embedding], [db_embedding])[0][0]

            if similarity > best_similarity and similarity > self.threshold:
                best_similarity = similarity
                best_name = name

        return best_name, best_similarity

    def real_time_recognition(self):
        """–†–µ–∂–∏–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if not self.embeddings_db:
            print("–°–Ω–∞—á–∞–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ª–∏—Ü–æ!")
            return

        cap = self.setup_camera()
        if cap is None:
            return

        print("üîç –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è... –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # –î–µ—Ç–µ–∫—Ü–∏—è –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            face_img, box = self.detect_face(frame)

            display_frame = frame.copy()

            if face_img is not None and box is not None:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º
                embedding = self.extract_face_features(face_img)
                name, confidence = self.recognize_face(embedding)

                x1, y1, x2, y2 = box
                color = (0, 255, 0) if name != "Unknown" else (0, 0, 255)

                # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É –∏ —Ç–µ–∫—Å—Ç
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 3)
                cv2.putText(display_frame, f"{name}", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                cv2.putText(display_frame, f"Confidence: {confidence:.2f}", (x1, y1 - 40),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                # –°—Ç–∞—Ç—É—Å
                status = "‚úÖ VERIFIED" if name != "Unknown" else "‚ùå UNKNOWN"
                cv2.putText(display_frame, status, (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            else:
                cv2.putText(display_frame, "üîç Searching for face...", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

            cv2.imshow('Face Recognition - Press Q to quit', display_frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()


def test_camera_simple():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –∫–∞–º–µ—Ä—ã"""
    print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É...")

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå –ö–∞–º–µ—Ä–∞ 0 –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, –ø—Ä–æ–±—É–µ–º –∫–∞–º–µ—Ä—É 1...")
        cap = cv2.VideoCapture(1)

    if cap.isOpened():
        print("‚úÖ –ö–∞–º–µ—Ä–∞ –Ω–∞–π–¥–µ–Ω–∞! –ü–æ–∫–∞–∂–∏—Ç–µ –ª–∏—Ü–æ –¥–ª—è —Ç–µ—Å—Ç–∞...")

        for i in range(50):  # 50 –∫–∞–¥—Ä–æ–≤
            ret, frame = cap.read()
            if ret:
                # –ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                face_cascade = cv2.CascadeClassifier(
                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                )
                faces = face_cascade.detectMultiScale(gray, 1.1, 5)

                for (x, y, w, h) in faces:
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    cv2.putText(frame, "Face Detected!", (x, y - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                cv2.imshow('Camera Test - Press any key to close', frame)

                if cv2.waitKey(1) & 0xFF != 255:
                    break
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä")
                break

        cap.release()
        cv2.destroyAllWindows()
        print("‚úÖ –¢–µ—Å—Ç –∫–∞–º–µ—Ä—ã –∑–∞–≤–µ—Ä—à–µ–Ω")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")


def main():
    print("=" * 60)
    print("üîê –°–ò–°–¢–ï–ú–ê –ë–ò–û–ú–ï–¢–†–ò–ß–ï–°–ö–û–ô –ò–î–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–ò")
    print("=" * 60)

    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É
    test_camera_simple()

    recognizer = WorkingFaceRecognition(threshold=0.6)

    while True:
        print("\n" + "=" * 50)
        print("–ú–ï–ù–Æ:")
        print("1. üì∑ –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ–µ –ª–∏—Ü–æ")
        print("2. üîç –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
        print("3. üë• –ü–æ–∫–∞–∑–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        print("4. üß™ –¢–µ—Å—Ç –∫–∞–º–µ—Ä—ã")
        print("5. üö™ –í—ã—Ö–æ–¥")
        print("=" * 50)

        choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (1-5): ").strip()

        if choice == '1':
            name = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ –∏–º—è: ").strip()
            if name:
                recognizer.register_face(name)
            else:
                print("‚ùå –ò–º—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º!")

        elif choice == '2':
            recognizer.real_time_recognition()

        elif choice == '3':
            if recognizer.embeddings_db:
                print(f"\nüìä –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏: {list(recognizer.embeddings_db.keys())}")
            else:
                print("\nüìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞")

        elif choice == '4':
            test_camera_simple()

        elif choice == '5':
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break

        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä!")


if __name__ == "__main__":
    main()