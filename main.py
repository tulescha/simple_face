import sys
import cv2
import numpy as np
from PyQt5 import QtWidgets, QtCore, QtGui
from ui_main import Ui_MainWindow
from face_recognition import FaceRecognitionSystem
import threading
import time


class VideoThread(QtCore.QThread):
    """–ü–æ—Ç–æ–∫ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã"""
    change_pixmap_signal = QtCore.pyqtSignal(np.ndarray)
    recognition_result = QtCore.pyqtSignal(str, float)

    def __init__(self, recognizer):
        super().__init__()
        self.recognizer = recognizer
        self.running = True
        self.recognition_enabled = False

    def run(self):
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
            return

        while self.running:
            ret, frame = cap.read()
            if ret:
                # –û—Ç—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                frame = cv2.flip(frame, 1)

                if self.recognition_enabled:
                    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
                    processed_frame, name = self.recognizer.process_frame(frame)
                    self.change_pixmap_signal.emit(processed_frame)

                    # –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if name and name != "Unknown":
                        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        face, box = self.recognizer.detector.detect(frame)
                        if face is not None:
                            features = self.recognizer.model.extract_features(face)
                            best_sim = 0.0
                            for db_features in self.recognizer.db.all_faces().values():
                                sim = self.recognizer._cosine_similarity(features, db_features)
                                if sim > best_sim:
                                    best_sim = sim
                            self.recognition_result.emit(name, best_sim)
                else:
                    # –ü—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –±–µ–∑ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
                    self.change_pixmap_signal.emit(frame)

            time.sleep(0.03)  # ~30 FPS

        cap.release()

    def stop(self):
        self.running = False
        self.recognition_enabled = False


class MainApp(QtWidgets.QMainWindow):
    def __init__(self):
        super(MainApp, self).__init__()
        self.ui = Ui_MainWindow()
        self.ui.setupUi(self)

        self.recognizer = FaceRecognitionSystem()

        # –°–æ–∑–¥–∞–µ–º QLabel –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ UI
        if not hasattr(self.ui, 'video_label'):
            self.video_label = QtWidgets.QLabel(self.ui.centralwidget)
            self.video_label.setGeometry(QtCore.QRect(300, 50, 480, 360))
            self.video_label.setStyleSheet("background-color: black; border: 2px solid gray;")
            self.video_label.setAlignment(QtCore.Qt.AlignCenter)
            self.video_label.setText("–ö–∞–º–µ—Ä–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞")
            self.video_label.setMinimumSize(480, 360)

        # –ü–æ—Ç–æ–∫ –¥–ª—è –≤–∏–¥–µ–æ
        self.video_thread = VideoThread(self.recognizer)
        self.video_thread.change_pixmap_signal.connect(self.update_image)
        self.video_thread.recognition_result.connect(self.on_recognition_result)

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º –∫–Ω–æ–ø–∫–∏ (–±–µ–∑ –∫–Ω–æ–ø–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–∞–º–µ—Ä—ã)
        self.ui.btnRegister.clicked.connect(self.register_user)
        self.ui.btnRecognize.clicked.connect(self.toggle_recognition)
        self.ui.btnShowDB.clicked.connect(self.show_db)
        self.ui.btnThresholds.clicked.connect(self.set_thresholds)
        self.ui.btnExit.clicked.connect(self.close)

        # –õ–æ–≥-–≤–∏–¥–∂–µ—Ç
        self.log_widget = self.ui.textBrowser

        # –°—Ç–∞—Ç—É—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self.recognition_active = False

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∫–∞–º–µ—Ä—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        self.start_camera()

        self.log("üöÄ –°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü –∑–∞–ø—É—â–µ–Ω–∞")
        self.log("üëâ –ù–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è' –¥–ª—è –Ω–∞—á–∞–ª–∞")

    def start_camera(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
        if not self.video_thread.isRunning():
            self.video_thread.start()
            self.log("üìπ –ö–∞–º–µ—Ä–∞ –∑–∞–ø—É—â–µ–Ω–∞")

    def update_image(self, cv_img):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ QLabel"""
        qt_img = self.convert_cv_qt(cv_img)
        if hasattr(self.ui, 'video_label'):
            self.ui.video_label.setPixmap(qt_img)
        else:
            self.video_label.setPixmap(qt_img)

    def convert_cv_qt(self, cv_img):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenCV image –≤ QPixmap"""
        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        bytes_per_line = ch * w
        convert_to_Qt_format = QtGui.QImage(rgb_image.data, w, h, bytes_per_line, QtGui.QImage.Format_RGB888)
        p = convert_to_Qt_format.scaled(480, 360, QtCore.Qt.KeepAspectRatio)
        return QtGui.QPixmap.fromImage(p)

    def on_recognition_result(self, name, confidence):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if confidence >= self.recognizer.high_thr:
            self.log(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω: {name} ({confidence:.2f})")
        elif confidence >= self.recognizer.low_thr:
            self.log(f"‚ö† –í–æ–∑–º–æ–∂–Ω–æ: {name}? ({confidence:.2f})")
        else:
            self.log(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π ({confidence:.2f})")

    def log(self, text):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        if self.log_widget:
            self.log_widget.append(text)
            scrollbar = self.log_widget.verticalScrollBar()
            scrollbar.setValue(scrollbar.maximum())
        print(f"[LOG] {text}")

    def register_user(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if self.recognition_active:
            self.log("‚ùå –°–Ω–∞—á–∞–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ!")
            return

        name, ok = QtWidgets.QInputDialog.getText(self, "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è", "–í–≤–µ–¥–∏—Ç–µ –∏–º—è:")
        if ok and name:
            if name in self.recognizer.db.all_faces():
                self.log(f"‚ö† –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                return

            self.log(f"üîç –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è {name}... –°–º–æ—Ç—Ä–∏—Ç–µ –≤ –∫–∞–º–µ—Ä—É!")

            # –ñ–¥–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ª–∏—Ü–∞
            face_detected = False
            for attempt in range(50):
                # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–¥ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∫–∞–¥—Ä–∞ –∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞
                time.sleep(0.1)

                # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏–º–∏—Ç–∏—Ä—É–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ª–∏—Ü–∞
                if attempt == 25:
                    face_detected = True
                    break

            if face_detected:
                # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ features (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –ª–∏—Ü–∞)
                dummy_features = np.random.rand(512).astype(np.float32)
                self.recognizer.db.add_face(name, dummy_features)
                self.log(f"üéâ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {name} —É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω!")
            else:
                self.log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –ª–∏—Ü–æ –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏")

    def toggle_recognition(self):
        """–í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if not self.recognizer.db.has_faces():
            self.log("‚ùå –ë–∞–∑–∞ –ø—É—Å—Ç–∞! –°–Ω–∞—á–∞–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
            return

        if not self.recognition_active:
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            self.video_thread.recognition_enabled = True
            self.recognition_active = True
            self.ui.btnRecognize.setText("–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ")
            self.ui.btnRecognize.setStyleSheet("background-color: orange;")
            self.log("üîç –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ...")
        else:
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            self.video_thread.recognition_enabled = False
            self.recognition_active = False
            self.ui.btnRecognize.setText("–ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
            self.ui.btnRecognize.setStyleSheet("")
            self.log("üõë –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

    def show_db(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        faces = self.recognizer.db.all_faces()
        if faces:
            user_list = "\n".join([f"‚Ä¢ {name}" for name in faces.keys()])
            self.log(f"üë• –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ ({len(faces)}):\n{user_list}")
        else:
            self.log("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞")

    def set_thresholds(self):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ä–æ–≥–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        current_low = self.recognizer.low_thr
        current_high = self.recognizer.high_thr

        low, ok1 = QtWidgets.QInputDialog.getDouble(
            self, "–ù–∏–∂–Ω–∏–π –ø–æ—Ä–æ–≥",
            "–ü–æ—Ä–æ–≥ –¥–ª—è '—Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ' —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:",
            current_low, 0.1, 0.9, 2
        )
        if not ok1:
            return

        high, ok2 = QtWidgets.QInputDialog.getDouble(
            self, "–í–µ—Ä—Ö–Ω–∏–π –ø–æ—Ä–æ–≥",
            "–ü–æ—Ä–æ–≥ –¥–ª—è '—É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ' —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:",
            current_high, low, 1.0, 2
        )
        if not ok2:
            return

        self.recognizer.low_thr = low
        self.recognizer.high_thr = high
        self.log(f"‚úÖ –ü–æ—Ä–æ–≥–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã:")
        self.log(f"   ‚Ä¢ –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: ‚â• {low:.2f}")
        self.log(f"   ‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: ‚â• {high:.2f}")

    def closeEvent(self, event):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞"""
        self.video_thread.stop()
        if self.video_thread.isRunning():
            self.video_thread.wait(2000)  # –ñ–¥–µ–º –¥–æ 2 —Å–µ–∫—É–Ω–¥
        event.accept()


if __name__ == "__main__":
    app = QtWidgets.QApplication(sys.argv)

    window = MainApp()
    window.setWindowTitle("–°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü")
    window.show()

    sys.exit(app.exec_())